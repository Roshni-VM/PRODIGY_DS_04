{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "TASK **4**"
      ],
      "metadata": {
        "id": "EFd00J0SCm-h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analyze and visualize sentiment patterns in social media data to understand public opinion and attitudes towards specific topics or brands."
      ],
      "metadata": {
        "id": "MjcgJFjXFfNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# üì¶ 1. Import Required Libraries\n",
        "# ================================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud\n",
        "import re\n",
        "from collections import Counter\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "YfNRcVIslxUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# üì• 2. Load and Inspect Dataset\n",
        "# ================================================\n",
        "df = pd.read_csv(\"/content/twitter_training.csv\", header=None)\n",
        "df.columns = ['Tweet_ID', 'Topic', 'Sentiment', 'Tweet']\n",
        "print(\"‚úÖ Dataset Loaded\")\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "VOM789Qr_3lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# üßπ 3. Data Cleaning & Preprocessing\n",
        "# ================================================\n",
        "# Basic cleaning: remove URLs, mentions, special chars\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'@[A-Za-z0-9_]+', '', text)  # Remove mentions\n",
        "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)  # Remove URLs\n",
        "    text = re.sub(r'#', '', text)  # Remove hashtag symbol\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove special chars\n",
        "    text = text.lower().strip()\n",
        "    return text\n",
        "\n",
        "df['clean_tweet'] = df['Tweet'].astype(str).apply(clean_text)\n",
        "\n",
        "# Remove stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "df['clean_tweet'] = df['clean_tweet'].apply(lambda x: \" \".join([word for word in x.split() if word not in stop_words]))"
      ],
      "metadata": {
        "id": "ZFaeRFH2_3PE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# üìä 4. Sentiment Distribution (Overall)\n",
        "# ================================================\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.countplot(data=df, x='Sentiment', order=df['Sentiment'].value_counts().index, palette='Set2')\n",
        "plt.title('Overall Sentiment Distribution', fontweight='bold')\n",
        "plt.xlabel('Sentiment')\n",
        "plt.ylabel('Tweet Count')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Pie Chart\n",
        "plt.figure(figsize=(6, 6))\n",
        "df['Sentiment'].value_counts().plot.pie(\n",
        "    autopct='%1.1f%%',\n",
        "    startangle=140,\n",
        "    colors=sns.color_palette('Set2'),\n",
        "    explode=(0.01, 0.01, 0.01, 0.01)\n",
        ")\n",
        "plt.title('Sentiment Proportion')\n",
        "plt.ylabel('')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "i4Gw3u-J_3Lk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# ‚òÅÔ∏è 5. Word Cloud per Sentiment\n",
        "# ================================================\n",
        "def generate_wordcloud(sentiment):\n",
        "    text = \" \".join(df[df['Sentiment'] == sentiment]['clean_tweet'])\n",
        "    wc = WordCloud(width=800, height=400, background_color='white', colormap='Set2').generate(text)\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.imshow(wc, interpolation='bilinear')\n",
        "    plt.axis('off')\n",
        "    plt.title(f\"Word Cloud - {sentiment}\", fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "for sentiment in df['Sentiment'].unique():\n",
        "    generate_wordcloud(sentiment)"
      ],
      "metadata": {
        "id": "I3-_BFxD_3JN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# üìà 6. Top Words by Sentiment\n",
        "# ================================================\n",
        "def plot_top_words(sentiment, n=15):\n",
        "    words = \" \".join(df[df['Sentiment'] == sentiment]['clean_tweet']).split()\n",
        "    most_common = Counter(words).most_common(n)\n",
        "    word_df = pd.DataFrame(most_common, columns=['Word', 'Count'])\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    sns.barplot(data=word_df, x='Count', y='Word', palette='Set2')\n",
        "    plt.title(f\"Top {n} Words - {sentiment}\", fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "for sentiment in df['Sentiment'].unique():\n",
        "    plot_top_words(sentiment)"
      ],
      "metadata": {
        "id": "3taQpnsQ_3GY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# üß† 7. Topic-Level Sentiment Analysis\n",
        "# ================================================\n",
        "# Get top 5 topics by tweet count\n",
        "top_topics = df['Topic'].value_counts().head(5).index\n",
        "\n",
        "for topic in top_topics:\n",
        "    topic_df = df[df['Topic'] == topic]\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    sns.countplot(data=topic_df, x='Sentiment', order=['Positive', 'Neutral', 'Negative', 'Irrelevant'], palette='Set3')\n",
        "    plt.title(f'Sentiment Distribution for Topic: {topic}', fontweight='bold')\n",
        "    plt.ylabel('Tweet Count')\n",
        "    plt.xlabel('Sentiment')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Rs_P6Ns3_3Ea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ **Conclusion**\n",
        "\n",
        "This study successfully accomplished the objective of analyzing and visualizing sentiment patterns in social media data to gain a deeper understanding of public opinion and attitudes toward specific topics and brands. Utilizing a comprehensive Twitter dataset, the project applied a structured methodology encompassing data cleaning, sentiment categorization, and multi-level visual exploration.\n",
        "\n",
        "The key findings and contributions of this analysis are as follows:\n",
        "\n",
        "Effective Preprocessing of Textual Data: Social media content was systematically cleaned to remove noise such as user mentions, hyperlinks, special characters, and stopwords, resulting in a refined corpus suitable for sentiment analysis.\n",
        "\n",
        "Exploratory Analysis of Sentiment Distribution: The overall sentiment landscape was visualized through bar and pie charts, revealing a predominance of both positive and negative sentiments, alongside a notable proportion of neutral and irrelevant expressions.\n",
        "\n",
        "Lexical Analysis by Sentiment Category: Word cloud visualizations and frequency-based plots highlighted the most frequently used terms within each sentiment class, offering insight into common linguistic patterns and emotional expressions.\n",
        "\n",
        "Sentiment Analysis at the Topic Level: By disaggregating sentiment by topic or brand, the analysis provided nuanced insights into public perception of specific entities, which is critical for brand monitoring and strategic communication."
      ],
      "metadata": {
        "id": "Mv2SCyRnQexU"
      }
    }
  ]
}